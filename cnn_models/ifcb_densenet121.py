# -*- coding: utf-8 -*-
"""Edited script version of notebook used to create DenseNet based model.

Notes:
- Originally generated by Colaboratory.
- Original file is located at
    https://colab.research.google.com/drive/1HjXQkzQ6bOzfuoJXv1KjtLEFaP8pX_yG
- Trained on labeled dataset provided by Alexis Fischer - Kudela Lab (UCSC)
- Validation accuracy of 0.9848 after 36 epochs
"""
import click
import tensorflow as tf
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint


def create_data_generators(path_to_training, path_to_validation, batch_size=200, target_size=(224, 224)):
    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        horizontal_flip=True,
        vertical_flip=True
    )
    train_generator = train_datagen.flow_from_directory(
        path_to_training,
        target_size=target_size,
        batch_size=batch_size,
        class_mode='categorical'
    )
    validation_generator = test_datagen.flow_from_directory(
        path_to_validation,
        target_size=target_size,
        batch_size=batch_size,
        class_mode='categorical'
    )
    return train_generator, validation_generator


def create_model():
    base_model = DenseNet121(
        weights='imagenet',
        include_top=False,
        pooling='avg'
    )

    # Add new fully connected layers for ifcb
    # dense layer to classify with softmax
    model_output = base_model.output
    model_output = Dense(1024, activation='relu')(model_output)
    model_output = Dense(50, activation='softmax')(model_output)
    model = Model(inputs=base_model.input, outputs=model_output)

    # Only train the dense layers, user transfer learning for the rest
    for layer in model.layers[:-2]:
        layer.trainable = False
    for layer in model.layers[-2::]:
        layer.trainable = True

    model.compile(
        optimizer='Adam',
        loss='categorical_crossentropy',
        metrics=['categorical_accuracy'],
    )

    return model


def train_model(model, train_generator, validation_generator, save_dir, batch_size):
    checkpoint_cb = ModelCheckpoint(
        filepath=save_dir,
        save_weights_only=False,
        monitor='loss',
        mode='min',
        save_best_only=True
    )
    learning_rate_cb = ReduceLROnPlateau(
        monitor='loss',
        factor=0.3,
        patience=2,
        min_lr=0.0001
    )
    stop_early_cb = EarlyStopping(
        monitor='loss',
        min_delta=0,
        patience=2,
    )
    with tf.device('/device:GPU:0'):
        model.fit(
            train_generator,
            epochs=40,
            steps_per_epoch=train_generator.samples // batch_size,
            validation_data=validation_generator,
            validation_freq=validation_generator.samples // batch_size,
            callbacks=[checkpoint_cb, learning_rate_cb, stop_early_cb]
        )
    model.save(save_dir)


@click.command()
@click.argument('output_dir')
@click.argument('train_path')
@click.argument('val_path')
@click.option('--batch_size', default=200, help='batch size')
def main(output_dir, train_path, val_path, batch_size):
    train_gen, val_gen = create_data_generators(train_path, val_path, batch_size)
    model = create_model()
    train_model(model, train_gen, val_gen, output_dir, batch_size)


if __name__ == '__main__':
    main()
